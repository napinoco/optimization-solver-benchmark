# Optimization Solver Benchmark System - Simplified Design

This document provides technical specifications for the **simplified** optimization solver benchmark system focused on reliability and maintainability.

---

## System Architecture

### Simplified Data Flow Architecture
```
LOCAL DEVELOPMENT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Problem   â”‚â”€â”€â”€â–¶â”‚   Solver     â”‚â”€â”€â”€â–¶â”‚   Result    â”‚
â”‚   Loading   â”‚    â”‚   Execution  â”‚    â”‚  Collection â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validation â”‚    â”‚  Environment â”‚    â”‚  Database   â”‚
â”‚   & Caching â”‚    â”‚    Capture   â”‚    â”‚   Storage   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚   Report    â”‚
                                     â”‚ Generation  â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚  Commit to  â”‚
                                     â”‚   docs/     â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

GITHUB ACTIONS (Publishing Only):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pre-built  â”‚â”€â”€â”€â–¶â”‚   GitHub     â”‚
â”‚    docs/    â”‚    â”‚    Pages     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Interaction (Simplified)
```
LOCAL DEVELOPMENT:
â”œâ”€â”€ Problem Loading (Local files only)
â”œâ”€â”€ Python Solver Execution (CVXPY + SciPy)
â”œâ”€â”€ Result Collection & Database Storage
â”œâ”€â”€ HTML Report Generation
â”œâ”€â”€ Data Export (JSON/CSV)
â””â”€â”€ Commit Generated Files

GITHUB ACTIONS (Minimal):
â”œâ”€â”€ PR Preview (Lightweight benchmark + publish)
â””â”€â”€ Main Branch Publishing (Static file deployment only)
```

---

## File and Directory Structure (Simplified)

```
optimization-solver-benchmark/
â”œâ”€â”€ README.md                    # Project overview and quick start
â”œâ”€â”€ architecture.md              # High-level system overview  
â”œâ”€â”€ CLAUDE.md                    # AI assistant integration context
â”œâ”€â”€ LICENSE                      # MIT license
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ deploy-pages.yml      # Publish pre-built docs/ to GitHub Pages
â”‚       â””â”€â”€ pr-preview.yml        # PR preview with lightweight benchmark
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ benchmark_config.yaml    # Local benchmark execution settings
â”‚   â”œâ”€â”€ solvers.yaml              # Python solver definitions only
â”‚   â”œâ”€â”€ site_config.yaml          # Author and site metadata
â”‚   â””â”€â”€ backend_templates/        # CVXPY backend configurations
â”‚       â”œâ”€â”€ clarabel.yaml
â”‚       â”œâ”€â”€ scs.yaml
â”‚       â”œâ”€â”€ ecos.yaml
â”‚       â””â”€â”€ osqp.yaml
â”‚
â”œâ”€â”€ problems/
â”‚   â””â”€â”€ light_set/               # Local problems only
â”‚       â”œâ”€â”€ lp/                  # Linear programming (.mps files)
â”‚       â”œâ”€â”€ qp/                  # Quadratic programming (.qps files)
â”‚       â”œâ”€â”€ socp/                # Second-order cone programming (Python)
â”‚       â””â”€â”€ sdp/                 # Semidefinite programming (Python)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ benchmark/
â”‚   â”‚   â”œâ”€â”€ runner.py             # Benchmark execution engine
â”‚   â”‚   â”œâ”€â”€ solver_interface.py   # Solver abstraction layer
â”‚   â”‚   â”œâ”€â”€ problem_loader.py     # Problem loading (local only)
â”‚   â”‚   â”œâ”€â”€ result_collector.py   # Result collection and aggregation
â”‚   â”‚   â”œâ”€â”€ backend_selector.py   # CVXPY backend selection
â”‚   â”‚   â””â”€â”€ environment_info.py   # Environment information gathering
â”‚   â”‚
â”‚   â”œâ”€â”€ solvers/
â”‚   â”‚   â””â”€â”€ python/               # Python solvers only
â”‚   â”‚       â”œâ”€â”€ cvxpy_runner.py   # CVXPY execution with multiple backends
â”‚   â”‚       â””â”€â”€ scipy_runner.py   # SciPy optimization suite
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py             # SQLAlchemy data models
â”‚   â”‚   â””â”€â”€ classification_storage.py # Problem classification storage
â”‚   â”‚
â”‚   â”œâ”€â”€ reporting/
â”‚   â”‚   â”œâ”€â”€ simple_html_generator.py  # Simple HTML report generation
â”‚   â”‚   â”œâ”€â”€ data_publisher.py     # JSON/CSV data publishing
â”‚   â”‚   â”œâ”€â”€ data_validator.py     # Result validation
â”‚   â”‚   â”œâ”€â”€ export.py             # Multi-format data export
â”‚   â”‚   â””â”€â”€ statistics.py         # Statistical calculations
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ statistical_analysis.py  # Statistical analysis
â”‚   â”‚   â”œâ”€â”€ performance_profiler.py  # Performance profiling
â”‚   â”‚   â””â”€â”€ analytics_runner.py   # Analytics execution
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config_loader.py      # Configuration loading
â”‚       â”œâ”€â”€ logger.py             # Structured logging
â”‚       â”œâ”€â”€ validation.py         # Data validation utilities
â”‚       â”œâ”€â”€ problem_classifier.py # Problem type classification
â”‚       â””â”€â”€ solver_diagnostics.py # Solver capability detection
â”‚
â”œâ”€â”€ docs/                        # GitHub Pages output (PRE-BUILT)
â”‚   â”œâ”€â”€ index.html               # Main dashboard (committed)
â”‚   â”œâ”€â”€ solver_comparison.html   # Solver performance comparison (committed)
â”‚   â”œâ”€â”€ problem_analysis.html    # Problem-wise analysis (committed)
â”‚   â”œâ”€â”€ results_matrix.html      # Problems Ã— solvers matrix (committed)
â”‚   â”œâ”€â”€ statistical_analysis.html # Statistical analysis report (committed)
â”‚   â”œâ”€â”€ performance_profiling.html # Performance profiling report (committed)
â”‚   â”œâ”€â”€ environment_info.html    # Environment information (committed)
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ css/style.css        # Custom styles (committed)
â”‚   â”‚   â””â”€â”€ js/                  # JavaScript for interactivity (committed)
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ results.json         # Complete benchmark results (committed)
â”‚       â”œâ”€â”€ summary.json         # Summary statistics (committed)
â”‚       â”œâ”€â”€ metadata.json        # Environment and configuration data (committed)
â”‚       â”œâ”€â”€ results.csv          # CSV export of results (committed)
â”‚       â”œâ”€â”€ statistical_analysis_report.json (committed)
â”‚       â””â”€â”€ performance_profiling_report.json (committed)
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ results.db               # SQLite database (committed)
â”‚   â”œâ”€â”€ schema.sql               # Database schema definition
â”‚   â””â”€â”€ schema_enhancement.sql   # Schema updates and enhancements
â”‚
â”œâ”€â”€ requirements/
â”‚   â”œâ”€â”€ base.txt                 # Core dependencies
â”‚   â”œâ”€â”€ python.txt               # Python solver dependencies
â”‚   â””â”€â”€ export.txt               # Export functionality dependencies
â”‚
â”œâ”€â”€ logs/                        # Log files (local only, .gitignore)
â”‚   â””â”€â”€ benchmark.log            # Structured execution logs
â”‚
â””â”€â”€ tests/                       # Test suite (cleaned up)
    â”œâ”€â”€ unit/                    # Unit tests
    â”œâ”€â”€ integration/             # Integration tests
    â””â”€â”€ fixtures/                # Test data and fixtures
```

---

## Core Components (Simplified)

### 1. GitHub Actions Workflows (Minimal)

#### deploy-pages.yml - Static File Publishing Only
```yaml
# Key features:
# - Triggers on push to main branch
# - Publishes PRE-BUILT docs/ folder to GitHub Pages
# - No benchmark execution in CI
# - Fast and reliable deployment
# - Preserves PR preview subdirectories
```

#### pr-preview.yml - Pull Request Preview System
```yaml
# Key features:
# - Auto-deploy PR previews to gh-pages/pr-preview/pr-{number}/
# - Lightweight benchmark with scipy,clarabel_cvxpy,scs_cvxpy and light_set
# - Auto-cleanup when PR closed
# - Preview banners and metadata injection
# - Comments with preview URLs on PRs
```

### 2. Configuration Management (Simplified)

#### benchmark_config.yaml - Local Execution Settings
```yaml
benchmark:
  timeout: 300                   # Solver timeout in seconds
  parallel_jobs: 1               # CPU core utilization (fair comparison)
  problem_sets:
    light_set: "problems/light_set"   # Only local problems
  
reporting:
  formats: ["html", "json", "csv"]
  include_environment_info: true
  include_statistical_analysis: true

database:
  path: "database/results.db"   # Local SQLite database

output:
  reports_dir: "docs"            # Pre-built HTML files
```

#### solvers.yaml - Python Solver Definitions Only
```yaml
solvers:
  scipy:
    type: python
    module: scripts.solvers.python.scipy_runner
    class: ScipySolver
    
  cvxpy:
    type: python  
    module: scripts.solvers.python.cvxpy_runner
    class: CVXPYSolver
    backends: [CLARABEL, SCS, ECOS, OSQP]  # Multi-backend support
```

### 3. Benchmark Execution Engine

#### runner.py - Orchestration Controller
```python
class BenchmarkRunner:
    """
    Main benchmark execution controller
    - Manages parallel execution across problems and solvers
    - Handles timeouts and error recovery
    - Collects and aggregates results
    - Provides progress reporting and logging
    """
```

#### solver_interface.py - Abstraction Layer
```python
class SolverInterface(ABC):
    """
    Abstract base class for all solvers
    - Standardized solve() method signature
    - Consistent result format (SolverResult dataclass)
    - Error handling and timeout management
    - Environment compatibility checking
    """
```

#### backend_selector.py - CVXPY Backend Management
```python
class BackendSelector:
    """
    Intelligent CVXPY backend selection
    - Problem type compatibility matrix
    - Solver capability detection
    - Fallback mechanism for failed backends
    - Performance-based recommendations
    """
```

### 4. Database Layer

#### Schema Design
```sql
-- Core tables for benchmark results
CREATE TABLE benchmarks (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME,
    environment_info TEXT,
    git_commit TEXT,
    configuration_hash TEXT
);

CREATE TABLE results (
    id INTEGER PRIMARY KEY,
    benchmark_id INTEGER,
    solver_name TEXT,
    problem_name TEXT,
    problem_type TEXT,
    solve_time REAL,
    status TEXT,
    objective_value REAL,
    duality_gap REAL,
    error_message TEXT,
    FOREIGN KEY (benchmark_id) REFERENCES benchmarks (id)
);

CREATE TABLE problems (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE,
    problem_type TEXT,
    file_path TEXT,
    variables INTEGER,
    constraints INTEGER,
    difficulty TEXT
);

CREATE TABLE solvers (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE,
    solver_type TEXT,
    version TEXT,
    backend TEXT,
    environment TEXT
);
```

#### models.py - Data Models
```python
# SQLAlchemy models with validation
class BenchmarkResult:
    """Complete benchmark result with environment context"""
    
class SolverResult:
    """Individual solver execution result"""
    
class ProblemMetadata:
    """Problem characteristics and classification"""
```

### 5. Reporting System

#### simple_html_generator.py - Report Generation
```python
class SimpleHTMLGenerator:
    """
    Generates comprehensive HTML reports
    - Bootstrap 5 styling with responsive design
    - Chart.js visualizations for performance data
    - Multiple report types (dashboard, comparison, analysis)
    - Author attribution and metadata integration
    """
```

#### data_publisher.py - Data Export
```python
class DataPublisher:
    """
    Multi-format data publishing
    - JSON export for programmatic access
    - CSV export for spreadsheet analysis
    - Metadata export for reproducibility
    - Validation and quality assurance
    """
```

---

## Data Formats and Standards

### Result Data Schema
```json
{
  "benchmark_metadata": {
    "timestamp": "2025-12-15T10:30:00Z",
    "environment": {
      "platform": "macOS-14.5-arm64-arm-64bit",
      "python_version": "3.12.2",
      "cpu_cores": 8,
      "memory_gb": 24.0,
      "timezone": "JST (UTC+9.0)"
    },
    "configuration": {
      "timeout": 300,
      "parallel_jobs": 1,
      "problem_set": "light_set"
    }
  },
  "results": [
    {
      "solver": "CLARABEL (via CVXPY)",
      "problem": "SIMPLE_LP",
      "problem_type": "LP", 
      "solve_time": 0.0025,
      "status": "optimal",
      "objective_value": 5.98e-10,
      "duality_gap": null,
      "variables": 2,
      "constraints": 2
    }
  ]
}
```

### Problem Classification
```python
class ProblemType(Enum):
    LP = "Linear Programming"
    QP = "Quadratic Programming" 
    SOCP = "Second-Order Cone Programming"
    SDP = "Semidefinite Programming"
    
class DifficultyLevel(Enum):
    TRIVIAL = "Small problems for testing"
    EASY = "Standard benchmark problems"
    MEDIUM = "Challenging real-world problems"
    HARD = "Large-scale or ill-conditioned problems"
```

---

## Performance Optimization

### Parallel Execution Strategy
```python
# Problem-level parallelization with CPU fairness
parallel_jobs: 1  # Fair CPU utilization for consistent benchmarking

# Solver-level sequential execution
# Ensures each solver gets dedicated CPU resources
# Prevents resource contention affecting results
```

### Caching and Storage
```python
# Problem file caching for external storage
# Solver installation state caching
# Result incremental updates
# Compressed data transfer for GitHub Pages
```

### GitHub Actions Optimization
```yaml
# Artifact handling for database persistence
# Staged deployment with dependency caching
# Efficient matrix execution for multiple environments
# Resource-aware job scheduling
```

---

## Extension Points

### Adding New Solvers
```python
# 1. Implement SolverInterface
class NewSolver(SolverInterface):
    def solve(self, problem: Problem) -> SolverResult:
        # Implementation here
        pass

# 2. Add configuration
# config/solvers.yaml:
new_solver:
  type: python
  module: scripts.solvers.python.new_solver
  class: NewSolver

# 3. Add dependencies
# requirements/python.txt:
new-solver-package>=1.0.0
```

### Adding Problem Types
```python
# 1. Extend problem loader
class ProblemLoader:
    def load_new_type(self, file_path: str) -> Problem:
        # Implementation for new format
        pass

# 2. Update classification
class ProblemClassifier:
    def classify_new_type(self, problem: Problem) -> ProblemMetadata:
        # Classification logic
        pass
```

---

## Security and Validation

### Input Validation
```python
# Problem file format validation
# Configuration value range checking  
# Solver result consistency verification
# Database input sanitization
```

### Environment Isolation
```python
# GitHub Actions sandboxed execution
# Explicit dependency management
# Timeout enforcement for solver execution
# Resource limit enforcement
```

### Data Integrity
```python
# Result validation against expected ranges
# Cross-solver consistency checks
# Environment reproducibility verification
# Configuration hash validation
```

---

## Monitoring and Operations

### Logging Framework
```python
# Structured logging with levels (DEBUG, INFO, WARNING, ERROR)
# Execution time measurement and reporting
# Error context capture for debugging
# Performance metrics collection
```

### Error Handling
```python
# Graceful solver failure handling
# Partial result collection on timeout
# Automatic retry for transient failures
# Comprehensive error reporting
```

### Deployment Pipeline
```python
# GitHub Actions automated testing
# Staged deployment with validation
# Rollback capability for failed deployments
# Environment consistency verification
```

---

*This detailed design document provides comprehensive technical specifications for implementation. For high-level concepts and project vision, see [basic_design.md](basic_design.md).*

---

## Current Implementation Status

### âœ… Completed Components (Sprint 1-2)
- **Core Simplification**: Removed Octave support, external storage components
- **GitHub Actions**: Simplified to static file publishing only
- **Local Workflow**: Complete benchmark execution and HTML report generation
- **Test Organization**: Cleaned up and organized test files in proper directory structure
- **Data Cleanup**: Removed test data, verified legitimate results only

### ðŸ”„ Current Capabilities
- **Solvers**: 5 Python-based solvers (SciPy, CLARABEL, SCS, ECOS, OSQP)
- **Problems**: 8 problems from light_set (LP, QP, SOCP, SDP)
- **Workflow**: `python main.py --all` runs complete local benchmark + report generation
- **Reports**: 7 HTML files + 6 data files generated in docs/
- **Database**: SQLite with 53 legitimate benchmark results

### ðŸ“‹ Implementation Notes
- **Local-First Approach**: All benchmark execution happens locally, CI only publishes
- **Pre-Built Artifacts**: HTML reports and data files are committed to repository
- **Clean Architecture**: Removed complexity, focused on reliability
- **Test Coverage**: Organized test suite with unit, integration, and debug tests

*Last Updated: June 2025 (Sprint 2 Complete)*